{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Amazon Review Data (2018)\n",
    "*Course*: DS807 \\\n",
    "*Authors*: August E. Wennerwald, Kasper Lin Hannberg, Oliver Klejst, Søren Pico, Thomas Fischer\n",
    "\n",
    "## Modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change your file path to your own "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m all_beauty \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(file_All_beauty, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m fashion \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mread_json(file_Fashion, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m luxury_beauty \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_luxury_beauty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#Check shape of datasets:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_beauty\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     13\u001b[0m       fashion\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     14\u001b[0m       luxury_beauty\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:804\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:1012\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         data \u001b[38;5;241m=\u001b[39m ensure_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m   1011\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:1040\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1038\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1040\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:1173\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1173\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:1366\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1366\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1369\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1370\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1372\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "#Import datasets\n",
    "file_All_beauty = \"/Users/oliverrasmussen/Desktop/AMAZON/All_Beauty_5.json\"\n",
    "file_Fashion = \"/Users/oliverrasmussen/Desktop/AMAZON/AMAZON_FASHION_5.json\"\n",
    "file_luxury_beauty = \"/Users/oliverrasmussen/Desktop/AMAZON/Luxury_Beauty_5.json\"\n",
    "\n",
    "# Load the gzipped JSON file into a pandas DataFrame\n",
    "all_beauty = pd.read_json(file_All_beauty, lines=True)\n",
    "fashion =  pd.read_json(file_Fashion, lines=True)\n",
    "luxury_beauty = pd.read_json(file_luxury_beauty, lines=True)\n",
    "\n",
    "#Check shape of datasets:\n",
    "print(all_beauty.shape,\n",
    "      fashion.shape,\n",
    "      luxury_beauty.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   overall  verified   reviewTime      reviewerID        asin  \\\n",
      "0        5      True   09 1, 2016  A3CIUOJXQ5VDQ2  B0000530HU   \n",
      "1        5      True  11 14, 2013  A3H7T87S984REU  B0000530HU   \n",
      "2        1      True  08 18, 2013  A3J034YH7UG4KT  B0000530HU   \n",
      "\n",
      "                                               style  reviewerName  \\\n",
      "0  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...      Shelly F   \n",
      "1  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...  houserules18   \n",
      "2  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...          Adam   \n",
      "\n",
      "                                          reviewText            summary  \\\n",
      "0                   As advertised. Reasonably priced         Five Stars   \n",
      "1  Like the oder and the feel when I put it on my...  Good for the face   \n",
      "2  I bought this to smell nice after I shave.  Wh...       Smells awful   \n",
      "\n",
      "   unixReviewTime vote image  \n",
      "0      1472688000  NaN   NaN  \n",
      "1      1384387200  NaN   NaN  \n",
      "2      1376784000  NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "print(all_beauty.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall            int64\n",
       "verified            bool\n",
       "reviewTime        object\n",
       "reviewerID        object\n",
       "asin              object\n",
       "style             object\n",
       "reviewerName      object\n",
       "reviewText        object\n",
       "summary           object\n",
       "unixReviewTime     int64\n",
       "vote              object\n",
       "image             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_beauty.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in all_beauty: [0, 0, 0, 0, 0, 645, 0, 5, 5, 0, 4717, 5171]\n",
      "Missing values in fashion: [0, 0, 0, 0, 0, 69, 0, 16, 0, 0, 2879, 3070]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'luxury_beauty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing values in all_beauty:\u001b[39m\u001b[38;5;124m\"\u001b[39m, missing_values(all_beauty))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing values in fashion:\u001b[39m\u001b[38;5;124m\"\u001b[39m, missing_values(fashion))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing values in luxury_beauty:\u001b[39m\u001b[38;5;124m\"\u001b[39m, missing_values(\u001b[43mluxury_beauty\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'luxury_beauty' is not defined"
     ]
    }
   ],
   "source": [
    "#Now checking for missing values in column \"reviewText and update the datasets accordingly\n",
    "\n",
    "def missing_values(dataset):\n",
    "    missing = []\n",
    "    for column in dataset.columns:\n",
    "        missing.append(dataset[column].isna().sum())\n",
    "    return missing\n",
    "\n",
    "print(\"Missing values in all_beauty:\", missing_values(all_beauty))\n",
    "print(\"Missing values in fashion:\", missing_values(fashion))\n",
    "print(\"Missing values in luxury_beauty:\", missing_values(luxury_beauty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with Missing values in column \"reviewText\"\n",
    "all_beauty.dropna(subset=['reviewText'],inplace=True)\n",
    "fashion.dropna(subset=['reviewText'],inplace=True)\n",
    "luxury_beauty.dropna(subset=['reviewText'],inplace=True)\n",
    "\n",
    "#Check updated shape of datasets:\n",
    "print(all_beauty.shape,\n",
    "      fashion.shape,\n",
    "      luxury_beauty.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates review based on certain columns\n",
    "all_beauty.drop_duplicates(subset=['overall', 'reviewText', 'asin', 'reviewerID'], inplace=True)\n",
    "fashion.drop_duplicates(subset=['overall', 'reviewText', 'asin', 'reviewerID'], inplace=True)\n",
    "luxury_beauty.drop_duplicates(subset=['overall', 'reviewText', 'asin', 'reviewerID'], inplace=True)\n",
    "\n",
    "#Check updated shape of datasets:\n",
    "print(all_beauty.shape,\n",
    "      fashion.shape,\n",
    "      luxury_beauty.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text in \"reviewText\" to lower case\n",
    "all_beauty['reviewText'] = all_beauty.reviewText.str.lower()\n",
    "fashion['reviewText'] = fashion.reviewText.str.lower()\n",
    "luxury_beauty['reviewText'] = luxury_beauty.reviewText.str.lower()\n",
    "\n",
    "#Check first 5 columns of all_beauty to validate\n",
    "print(all_beauty['reviewText'].head(5))\n",
    "\n",
    "#check shape to validate rows are keeped\n",
    "print(all_beauty.shape,\n",
    "      fashion.shape,\n",
    "      luxury_beauty.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution analysis of our datasets:\n",
    "datasets = [all_beauty, fashion, luxury_beauty]\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    plt.hist(dataset['overall'], color=colors[i], edgecolor='black')\n",
    "    plt.title(f'Histogram')\n",
    "    plt.xlabel('Stars')\n",
    "    plt.ylabel('Number of reviews')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of the textual reviews\n",
    "#average, min and max lengths of reviews\n",
    "\n",
    "def review_lengths(df):\n",
    "    print(f'Average review length = {round(df[\"reviewText\"].str.len().mean(),0)} characters')\n",
    "    print(f'Min review length = {df[\"reviewText\"].str.len().min()} characters')\n",
    "    print(f'Max review length = {df[\"reviewText\"].str.len().max()} characters')\n",
    "\n",
    "review_lengths(all_beauty)\n",
    "review_lengths(fashion)\n",
    "review_lengths(luxury_beauty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Textvectorization layer - to see the most frequent words in sentences.\n",
    "max_tokens = 5214 #\n",
    "output_sequence_length = 500 # to capture the average reviews in luxury_beauty\n",
    "pad_to_max_tokens = True\n",
    "\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens,\n",
    "                                            output_sequence_length=output_sequence_length,\n",
    "                                            pad_to_max_tokens=pad_to_max_tokens)\n",
    "\n",
    "\n",
    "#Vocabulary and frequent words:\n",
    "def vocabulary_words(dataset):\n",
    "    text_dataset = dataset['reviewText']\n",
    "    encoder.adapt(text_dataset)\n",
    "    vocabulary = np.array(encoder.get_vocabulary())\n",
    "    print(f'Vocabulary size = {len(vocabulary)}')\n",
    "    print(f'20 most common words: {vocabulary[:20]}')\n",
    "\n",
    "vocabulary_words(all_beauty)\n",
    "vocabulary_words(fashion)\n",
    "vocabulary_words(luxury_beauty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to check for similarities with luxury_beauty in the top 20:\n",
    "all_beauty_words = ['', '[UNK]', 'the', 'i', 'and', 'it', 'a', 'this', 'to', 'is', 'my', 'of', 'for', 'in', 'that', 'but', 'love', 'product', 'hair', 'with']\n",
    "fashion_words = ['', '[UNK]', 'i', 'and', 'the', 'a', 'for', 'these', 'shoes', 'my', 'them', 'to', 'are', 'they', 'comfortable', 'in', 'of', 'very', 'fit', 'is']\n",
    "luxury_beauty_words = ['', '[UNK]', 'the', 'i', 'a', 'it', 'and', 'to', 'is', 'this', 'my', 'of', 'for', 'that', 'on', 'in', 'but', 'with', 'skin', 'not']\n",
    "\n",
    "common_words_all_beauty = set(all_beauty_words) & set(luxury_beauty_words)\n",
    "common_words_fashion = set(fashion_words) & set(luxury_beauty_words) \n",
    "\n",
    "print(f'Number of shared words with all_beauty: {len(common_words_all_beauty)}')\n",
    "print(f'Common words: {common_words_all_beauty}')\n",
    "\n",
    "print(f'Number of shared words with fashion: {len(common_words_fashion)}')\n",
    "print(f'Common words: {common_words_fashion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the top 20, we remove words we are not interested in by adding the words to a list.\n",
    "words = [#at first common words in the English language\n",
    "    #based on all_beauty:\n",
    "    '', 'to', 'with', 'this', 'it', '[UNK]', 'my', 'for', 'and', 'i', 'that',\n",
    "    'the', 'a', 'is', 'of', 'in', 'but', 'have', 'on', 'so', 'as', 'you', 'was', 'use',\n",
    "    'its', 'just', 'are', 'has', 'one', 'be', 'will',\n",
    "    'or', 'using', 'they', 'when', 'if',\n",
    "    'get', 'would', 'your', 'at', 'me',\n",
    "    'from', 'out', 'used', 'find',\n",
    "    'time',\n",
    "    #based on fashion:\n",
    "    'these', 'them', \n",
    "    'had', 'than', 'ive', 'day',\n",
    "    'im', 'am',\n",
    "    'because', 'an',\n",
    "    #based on luxury_beauty\n",
    "    'can', 'does', 'do',\n",
    "\n",
    "    #secondly, we remove commonly used words associated with shoes\n",
    "    #based on fashion:\n",
    "    'shoes', 'comfortable', 'fit', 'shoe', 'size', 'feet', 'wear', 'pair', 'support',\n",
    "    'nike', 'weight', 'lightweight',\n",
    "    'training', 'running'\n",
    "    ]\n",
    "\n",
    "#Now we run our frequency test again with the filtered vocabulary \n",
    "#We run the function several times and for each time filter out the words we are not interested in:\n",
    "#each line in \"words\" represent an iteration with the words left out.\n",
    "def vocabulary_words_filtered(dataset):\n",
    "    text_dataset = dataset['reviewText']\n",
    "    encoder.adapt(text_dataset)\n",
    "    vocabulary = np.array(encoder.get_vocabulary())\n",
    "    vocabulary_filtered = [word for word in vocabulary if word not in words]\n",
    "    print(f'Vocabulary size = {len(vocabulary_filtered)}')\n",
    "    print(f'20 most common words: {vocabulary_filtered[:20]}')\n",
    "\n",
    "vocabulary_words_filtered(all_beauty)\n",
    "vocabulary_words_filtered(fashion)\n",
    "vocabulary_words_filtered(luxury_beauty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to check for similarities with luxury_beauty in the top 20:\n",
    "all_beauty_words = ['love', 'product', 'hair', 'great', 'not', 'like', 'very', 'good', 'skin', 'shampoo', 'body', 'scent', 'all', 'smell', 'more', 'smells', 'really', 'well', 'soap', 'no']\n",
    "fashion_words = ['very', 'love', 'great', 'not', 'light', 'like', 'good', 'perfect', 'all', 'too', 'really', 'more', 'nice', 'feel', 'expected', 'super', 'color', 'work', 'no', 'dont']\n",
    "luxury_beauty_words = ['skin', 'not', 'product', 'like', 'very', 'color', 'hair', 'more', 'really', 'face', 'all', 'great', 'love', 'good', 'well', 'after', 'products', 'dont', 'no', 'up']\n",
    "\n",
    "common_words_all_beauty = set(all_beauty_words) & set(luxury_beauty_words)\n",
    "common_words_fashion = set(fashion_words) & set(luxury_beauty_words) \n",
    "\n",
    "print(f'Number of shared words with all_beauty: {len(common_words_all_beauty)}')\n",
    "print(f'Common words: {common_words_all_beauty}')\n",
    "\n",
    "print(f'Number of shared words with fashion: {len(common_words_fashion)}')\n",
    "print(f'Common words: {common_words_fashion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing column \"summary\"\n",
    "#Some data preparation - lower case words (we dont check for non values this time as this would remove rows containing text in \"reviewText\")\n",
    "\n",
    "all_beauty['summary'] = all_beauty.summary.str.lower()\n",
    "fashion['summary'] = fashion.summary.str.lower()\n",
    "luxury_beauty['summary'] = luxury_beauty.summary.str.lower()\n",
    "\n",
    "print(all_beauty['summary'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of texts in \"summary\":\n",
    "def summary_lengths(df):\n",
    "    print(f'Average review length = {round(df[\"summary\"].str.len().mean(),0)} characters')\n",
    "    print(f'Min review length = {df[\"summary\"].str.len().min()} characters')\n",
    "    print(f'Max review length = {df[\"summary\"].str.len().max()} characters')\n",
    "\n",
    "summary_lengths(all_beauty)\n",
    "summary_lengths(fashion)\n",
    "summary_lengths(luxury_beauty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prevalent words in summaries:\n",
    "max_tokens = 5214 #\n",
    "output_sequence_length = 209 # to capture the average review length in luxury_beauty\n",
    "pad_to_max_tokens = True\n",
    "\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens,\n",
    "                                            output_sequence_length=output_sequence_length,\n",
    "                                            pad_to_max_tokens=pad_to_max_tokens)\n",
    "\n",
    "#We run the frequency_test again by using the already existing function with a little modification as we are interested in column \"summary\"\n",
    "#We can use the filtered vocabulary from textReview again.\n",
    "def vocabulary_words_filtered(dataset):\n",
    "    text_dataset = dataset['summary']\n",
    "    #replace nan-values with \" \"\n",
    "    text_dataset = text_dataset.replace(np.nan, \" \")\n",
    "    encoder.adapt(text_dataset)\n",
    "    vocabulary = np.array(encoder.get_vocabulary())\n",
    "    vocabulary_filtered = [word for word in vocabulary if word not in words]\n",
    "    print(f'Vocabulary size = {len(vocabulary_filtered)}')\n",
    "    print(f'20 most common words: {vocabulary_filtered[:20]}')\n",
    "\n",
    "vocabulary_words_filtered(all_beauty)\n",
    "vocabulary_words_filtered(fashion)\n",
    "vocabulary_words_filtered(luxury_beauty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check for similarities with luxury_beauty\n",
    "all_beauty_words = ['stars', 'five', 'great', 'love', 'product', 'hair', 'good', 'scent', 'shampoo', 'best', 'body', 'favorite', 'wash', 'really', 'nice', 'like', 'shower', 'soap', 'smells', 'smell']\n",
    "fashion_words = ['stars', 'five', 'love', 'great', 'good', 'four', 'very', 'not', 'perfect', 'nice', 'what', 'like', 'wide', 'three', 'sneakers', 'light', 'color', 'best', 'feel', 'super']\n",
    "luxury_beauty_words = ['stars', 'great', 'five', 'color', 'love', 'not', 'skin', 'good', 'product', 'nice', 'very', 'works', 'like', 'scent', 'best', 'well', 'hair', 'cream', 'too', 'no']\n",
    "\n",
    "common_words_all_beauty = set(all_beauty_words) & set(luxury_beauty_words)\n",
    "common_words_fashion = set(fashion_words) & set(luxury_beauty_words) \n",
    "\n",
    "print(f'Number of shared words with all_beauty: {len(common_words_all_beauty)}')\n",
    "print(f'Common words: {common_words_all_beauty}')\n",
    "\n",
    "print(f'Number of shared words with fashion: {len(common_words_fashion)}')\n",
    "print(f'Common words: {common_words_fashion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow learner 1\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (5826, 6179), (5826,)\n",
      "Validation set: (1457, 6179), (1457,)\n",
      "Test set: (29955, 6179), (29955,)\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.98        44\n",
      "           2       1.00      0.84      0.91        31\n",
      "           3       1.00      0.82      0.90        87\n",
      "           4       0.97      0.78      0.86       158\n",
      "           5       0.95      1.00      0.97      1137\n",
      "\n",
      "    accuracy                           0.96      1457\n",
      "   macro avg       0.98      0.88      0.92      1457\n",
      "weighted avg       0.96      0.96      0.96      1457\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.00      0.00       986\n",
      "           2       0.00      0.00      0.00      1379\n",
      "           3       0.00      0.00      0.00      3534\n",
      "           4       0.22      0.00      0.00      7114\n",
      "           5       0.57      1.00      0.72     16942\n",
      "\n",
      "    accuracy                           0.56     29955\n",
      "   macro avg       0.29      0.20      0.15     29955\n",
      "weighted avg       0.39      0.56      0.41     29955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to prepare the data\n",
    "def prepare_data(df):\n",
    "    df['reviewText'] = df['reviewText'].fillna('').astype(str)\n",
    "    X = df['reviewText']\n",
    "    y = df['overall']  # Subtract 1 to make labels 0-based\n",
    "    return X, y\n",
    "\n",
    "# Loading datasets\n",
    "fashion = pd.read_csv('Training.csv')\n",
    "luxury_beauty = pd.read_csv('luxury_beauty_dataset.csv')\n",
    "\n",
    "# Preparing training and validation data from 'fashion'\n",
    "X_train_fashion, y_train_fashion = prepare_data(fashion)\n",
    "\n",
    "# Preparing test data from 'luxury_beauty'\n",
    "X_test_luxury_beauty, y_test_luxury_beauty = prepare_data(luxury_beauty)\n",
    "\n",
    "# Initialize a new TfidfVectorizer and fit-transform on both training and test data\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf.fit_transform(X_train_fashion)\n",
    "X_test_vectorized = tfidf.transform(X_test_luxury_beauty)\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_vectorized, y_train_fashion, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train_split.shape}, {y_train_split.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test_vectorized.shape}, {y_test_luxury_beauty.shape}\")\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Predictions and evaluation on validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "print(\"Validation Report:\")\n",
    "print(classification_report(y_val, y_val_pred))  \n",
    "\n",
    "# Predictions and evaluation on test set\n",
    "y_test_pred = rf_classifier.predict(X_test_vectorized)\n",
    "print(\"Test Report:\")\n",
    "print(classification_report(y_test_luxury_beauty, y_test_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset: 99.55%\n",
      "Accuracy on validation dataset: 95.74%\n",
      "Accuracy on test dataset: 56.45%\n"
     ]
    }
   ],
   "source": [
    "# Basline without HPT\n",
    "y_train_pred = rf_classifier.predict(X_train_split)\n",
    "train_accuracy = accuracy_score(y_train_split, y_train_pred)\n",
    "print(f\"Accuracy on training dataset: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict and evaluate on validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy on validation dataset: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "y_test_pred = rf_classifier.predict(X_test_vectorized)\n",
    "test_accuracy = accuracy_score(y_test_luxury_beauty, y_test_pred)\n",
    "print(f\"Accuracy on test dataset: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:18<00:54, 18.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m     12\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[1;32m     13\u001b[0m     min_samples_split\u001b[38;5;241m=\u001b[39mmin_samples_split,\n\u001b[1;32m     14\u001b[0m     min_samples_leaf\u001b[38;5;241m=\u001b[39mmin_samples_leaf,\n\u001b[1;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Apply cross-validation\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m cross_val_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m avg_accuracy \u001b[38;5;241m=\u001b[39m cross_val_scores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     21\u001b[0m results\u001b[38;5;241m.\u001b[39mappend([avg_accuracy, n_estimators, min_samples_split, min_samples_leaf])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameter list\n",
    "n_estimators_list = [10, 20, 200, 500]\n",
    "min_samples_split_list = [10, 15, 20]\n",
    "min_samples_leaf_list = [3, 5, 10, 15]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_estimators in tqdm.tqdm(n_estimators_list):\n",
    "    for min_samples_split in min_samples_split_list:\n",
    "        for min_samples_leaf in min_samples_leaf_list:\n",
    "            rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                random_state=42\n",
    "            )\n",
    "            # Apply cross-validation\n",
    "            cross_val_scores = cross_val_score(rf_classifier, X_train_split, y_train_split, cv=5)\n",
    "            avg_accuracy = cross_val_scores.mean()\n",
    "\n",
    "            results.append([avg_accuracy, n_estimators, min_samples_split, min_samples_leaf])\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Average Accuracy', 'n_estimators', 'min_samples_split', 'min_samples_leaf'])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with RandomizedSearchCV. Not a better result.\n",
    "# Define the parameter range for Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 20, 200, 500],\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [3, 5, 10, 15]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(rf_classifier, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Perform Random Search\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best score:\", random_search.best_score_)\n",
    "\n",
    "# Use the best model to predict on the validation set\n",
    "best_rf_classifier = random_search.best_estimator_\n",
    "y_val_pred = best_rf_classifier.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy with Best Model: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the row with the maximum average accuracy\n",
    "max_index = results_df['Average Accuracy'].idxmax()\n",
    "\n",
    "print(\"Index of the row with the maximum value in Average Accuracy:\", max_index)\n",
    "\n",
    "max_row = results_df.loc[max_index]\n",
    "print(\"Row with the maximum value in Average Accuracy:\")\n",
    "print(max_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the optimal hyperparameters\n",
    "optimal_rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the full training set\n",
    "optimal_rf_classifier.fit(X_train_vectorized, y_train_fashion)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = optimal_rf_classifier.predict(X_test_vectorized)\n",
    "\n",
    "\n",
    "test_report = classification_report(y_test_luxury_beauty, y_test_pred, zero_division=1)\n",
    "print(\"Test Report:\")\n",
    "print(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "y_train_pred = optimal_rf_classifier.predict(X_train_vectorized)\n",
    "accuracy_train = accuracy_score(y_train_fashion, y_train_pred)\n",
    "print(f'Accuracy on the training dataset with the optimal model: {round(accuracy_train * 100, 2)}%')\n",
    "\n",
    "# Re-evaluate on the validation set with the chosen model\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Accuracy on the validation dataset with the optimal model: {round(accuracy_val * 100, 2)}%')\n",
    "\n",
    "# Calculate the accuracy on the test dataset\n",
    "accuracy_test = accuracy_score(y_test_luxury_beauty, y_test_pred)\n",
    "print(f'Accuracy on the test dataset with the optimal model: {round(accuracy_test * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow learner 2\n",
    "\n",
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    df['reviewText'] = df['reviewText'].fillna('').astype(str)\n",
    "    X = df['reviewText']\n",
    "    y = df['overall'] \n",
    "    return X, y\n",
    "\n",
    "# Loading datasets\n",
    "fashion_df = pd.read_csv('Training.csv')\n",
    "luxury_beauty_df = pd.read_csv('luxury_beauty_dataset.csv')\n",
    "\n",
    "# Preparing training data (fashion)\n",
    "X_train_fashion, y_train_fashion = prepare_data(fashion_df)\n",
    "\n",
    "# Text vectorization for training data\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf.fit_transform(X_train_fashion)\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_vectorized, y_train_fashion, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preparing test data (luxury beauty)\n",
    "X_test_luxury_beauty, y_test_luxury_beauty = prepare_data(luxury_beauty_df)\n",
    "\n",
    "# Vectorization of test data \n",
    "X_test_vectorized = tfidf.transform(X_test_luxury_beauty)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test_vectorized.shape}, {y_test_luxury_beauty.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model with default hyperparameters or a baseline configuration\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Baseline accuracy on training dataset: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict and evaluate on the validation set\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Baseline accuracy on validation dataset: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "Cs = [0.1, 1.0, 10.0]\n",
    "decision_functions = ['ovr', 'ovo']\n",
    "degrees = [2, 3, 4]  # For the 'poly' kernel\n",
    "gammas = [0.1, 1, 10, 'scale', 'auto']  # For the 'rbf' kernel\n",
    "\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in Cs:\n",
    "        for decision_function in decision_functions:\n",
    "            if kernel == 'poly':\n",
    "                for degree in degrees:\n",
    "                    svm_current = svm.SVC(kernel=kernel, C=C, degree=degree, decision_function_shape=decision_function, probability=True)\n",
    "                    svm_current.fit(X_train, y_train)\n",
    "                    y_val_hat = svm_current.predict(X_val)\n",
    "                    accuracy = accuracy_score(y_val_hat, y_val)\n",
    "                    results.append([accuracy, kernel, C, decision_function, degree, 'NA'])\n",
    "            elif kernel == 'rbf':\n",
    "                for gamma in gammas:\n",
    "                    svm_current = svm.SVC(kernel=kernel, C=C, gamma=gamma, decision_function_shape=decision_function, probability=True)\n",
    "                    svm_current.fit(X_train, y_train)\n",
    "                    y_val_hat = svm_current.predict(X_val)\n",
    "                    accuracy = accuracy_score(y_val_hat, y_val)\n",
    "                    results.append([accuracy, kernel, C, decision_function, 'NA', gamma])\n",
    "            else:\n",
    "                # For 'linear' and other kernels where degree and gamma are not relevant\n",
    "                svm_current = svm.SVC(kernel=kernel, C=C, decision_function_shape=decision_function, probability=True)\n",
    "                svm_current.fit(X_train, y_train)\n",
    "                y_val_hat = svm_current.predict(X_val)\n",
    "                accuracy = accuracy_score(y_val_hat, y_val)\n",
    "                results.append([accuracy, kernel, C, decision_function, 'NA', 'NA'])\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Accuracy', 'Kernel', 'C', 'Decision function', 'Degree', 'Gamma'])\n",
    "\n",
    "# Sort the results\n",
    "print(results_df.sort_values(by='Accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top accuracy\n",
    "top_accuracy = results_df['Accuracy'].max()\n",
    "top_models = results_df[results_df['Accuracy'] == top_accuracy]\n",
    "print(top_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLY kernel with various hyperparameters\n",
    "Cs = [0.1, 1.0, 10.0]  \n",
    "degrees = [2, 3, 4, 5]  \n",
    "results = []\n",
    "\n",
    "# Train models with different combinations of C and degree\n",
    "for C in Cs:\n",
    "    for degree in degrees:\n",
    "        svm_current = svm.SVC(kernel='poly', C=C, degree=int(degree))  # Ensure degree is an integer\n",
    "        svm_current.fit(X_train, y_train)  # Training on the training set\n",
    "        y_val_hat = svm_current.predict(X_val)  # Predicting on the validation set\n",
    "        accuracy = accuracy_score(y_val_hat, y_val)  # Calculating accuracy\n",
    "        results.append([accuracy, C, degree])  # Storing results\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "results_df = pd.DataFrame(results, columns=['Accuracy', 'C', 'Degree'])\n",
    "\n",
    "# Identify the best model configuration\n",
    "best_model_config = results_df.sort_values(by='Accuracy', ascending=False).iloc[0]\n",
    "best_C = best_model_config['C']\n",
    "best_degree = int(best_model_config['Degree'])  # Ensure degree is an integer\n",
    "\n",
    "# Initialize and train the best model configuration on the full training set\n",
    "svm_best = svm.SVC(kernel='poly', C=best_C, degree=best_degree, probability=True)\n",
    "svm_best.fit(X_train, y_train)  \n",
    "\n",
    "# Predictions on the test set \n",
    "y_test_pred = svm_best.predict(X_test_vectorized)  \n",
    "\n",
    "# Evaluate performance on the test set\n",
    "accuracy_test = accuracy_score(y_test_luxury_beauty, y_test_pred)  # Evaluate accuracy on the test set\n",
    "print(f'Accuracy on test dataset with the best model: {round(accuracy_test * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "y_train_pred = svm_best.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Accuracy on training dataset with the best model: {round(accuracy_train * 100, 2)}%')\n",
    "\n",
    "# Re-evaluate on the validation set with the chosen model\n",
    "y_val_pred = svm_best.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Accuracy on validation dataset with the best model: {round(accuracy_val * 100, 2)}%')\n",
    "\n",
    "# The accuracy on the test set has already been calculated\n",
    "print(f'Accuracy on test dataset with the best model: {round(accuracy_test * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test_luxury_beauty, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision and recall with specified averaging method and handling of zero division\n",
    "precision = precision_score(y_test_luxury_beauty, y_test_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test_luxury_beauty, y_test_pred, average='weighted')\n",
    "\n",
    "# Print precision and recall\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC\n",
    "\n",
    "# Binarizing the output labels for multiclass\n",
    "y_test_binarized = label_binarize(y_test_luxury_beauty, classes=np.unique(y_test_luxury_beauty))\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_pred_prob = svm_best.predict_proba(X_test_vectorized)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown'] \n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {i+1} (AUC = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print AUC scores for each class\n",
    "for i in range(n_classes):\n",
    "    print(f'AUC score for class {i+1}: {roc_auc[i]:0.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Handle Class Imbalance\n",
    "\n",
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Data preparation\n",
    "X_train_fashion, y_train_fashion = prepare_data(fashion_df)\n",
    "X_test_luxury_beauty, y_test_luxury_beauty = prepare_data(luxury_beauty_df)\n",
    "\n",
    "# Text vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf.fit_transform(X_train_fashion)\n",
    "X_test_vectorized = tfidf.transform(X_test_luxury_beauty)\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_vectorized, y_train_fashion, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define SVM model (assuming best_C and best_degree are already defined)\n",
    "svm_model = svm.SVC(kernel='poly', C=best_C, degree=best_degree, probability=True)\n",
    "\n",
    "# Training and evaluation on original data\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_original = svm_model.predict(X_test_vectorized)\n",
    "print('Original SVM Classification report:\\n', classification_report(y_test_luxury_beauty, y_pred_original, zero_division=1))\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Training and evaluation on SMOTE-treated data\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_resampled = svm_model.predict(X_test_vectorized)\n",
    "print('SMOTE SVM Classification report:\\n', classification_report(y_test_luxury_beauty, y_pred_resampled, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set and calculate accuracy\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Accuracy on training dataset: {train_accuracy:.2f}')\n",
    "\n",
    "# Predict on the validation set and calculate accuracy\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Accuracy on validation dataset: {val_accuracy:.2f}')\n",
    "\n",
    "# Predict on the test set and calculate accuracy (already done)\n",
    "y_test_pred = svm_model.predict(X_test_vectorized)\n",
    "test_accuracy = accuracy_score(y_test_luxury_beauty, y_test_pred)\n",
    "print(f'Accuracy on test dataset: {test_accuracy:.2f}')\n",
    "\n",
    "# Classification report for the test dataset\n",
    "print('Test SVM Classification report:\\n', classification_report(y_test_luxury_beauty, y_test_pred, zero_division=1))\n",
    "\n",
    "# Apply SMOTE and retrain\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and calculate accuracy on the test set with the SMOTE-treated model\n",
    "y_test_pred_smote = svm_model.predict(X_test_vectorized)\n",
    "test_accuracy_smote = accuracy_score(y_test_luxury_beauty, y_test_pred_smote)\n",
    "print(f'Accuracy on test dataset with SMOTE: {test_accuracy_smote:.2f}')\n",
    "\n",
    "# Classification report for the test dataset with SMOTE\n",
    "print('SMOTE SVM Classification report:\\n', classification_report(y_test_luxury_beauty, y_test_pred_smote, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set with SMOTE-treated model\n",
    "y_train_pred_smote = svm_model.predict(X_train_resampled)\n",
    "\n",
    "# Predictions on the validation set with SMOTE-treated model\n",
    "# Note: SMOTE is typically only applied to the training data, not the validation data\n",
    "y_val_pred_smote = svm_model.predict(X_val)\n",
    "\n",
    "# Accuracy calculations\n",
    "train_accuracy_smote = accuracy_score(y_train_resampled, y_train_pred_smote)\n",
    "val_accuracy_smote = accuracy_score(y_val, y_val_pred_smote)\n",
    "test_accuracy_smote = accuracy_score(y_test_luxury_beauty, y_pred_resampled)\n",
    "\n",
    "# Printing accuracies\n",
    "print(f'Accuracy on training dataset with SMOTE: {train_accuracy_smote:.2f}')\n",
    "print(f'Accuracy on validation dataset with SMOTE: {val_accuracy_smote:.2f}')\n",
    "print(f'Accuracy on test dataset with SMOTE: {test_accuracy_smote:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Count of samples in each class before SMOTE\n",
    "class_counts_before = y_train.value_counts().sort_index()\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count of samples in each class after SMOTE\n",
    "class_counts_after = pd.Series(y_train_resampled).value_counts().sort_index()\n",
    "\n",
    "# Plot class balance before and after SMOTE\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Before SMOTE\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts_before.plot(kind='bar', color='coral')\n",
    "plt.title('Classes Before SMOTE')\n",
    "plt.xlabel('Class')\n",
    "\n",
    "plt.xticks(range(len(class_counts_before)), range(1, len(class_counts_before) + 1))  # Adjusting x-axis labels\n",
    "\n",
    "# After SMOTE\n",
    "plt.subplot(1, 2, 2)\n",
    "class_counts_after.plot(kind='bar', color='teal')\n",
    "plt.title('Classes After SMOTE')\n",
    "plt.xlabel('Class')\n",
    "\n",
    "plt.xticks(range(len(class_counts_after)), range(1, len(class_counts_after) + 1))  # Adjusting x-axis labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points before SMOTE\n",
    "num_samples_before = X_train.shape[0]\n",
    "\n",
    "# Number of data points after SMOTE\n",
    "num_samples_after = X_train_resampled.shape[0]\n",
    "\n",
    "print(f\"Number of data points before SMOTE: {num_samples_before}\")\n",
    "print(f\"Number of data points after SMOTE: {num_samples_after}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model on the expanded training data after SMOTE\n",
    "svm_model_after_smote = svm.SVC(kernel='poly', C=best_C, degree=best_degree, probability=True)\n",
    "svm_model_after_smote.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred_after_smote = svm_model_after_smote.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate the accuracy after SMOTE\n",
    "accuracy_after_smote = accuracy_score(y_test_luxury_beauty, y_pred_after_smote)\n",
    "\n",
    "# Compare the accuracy before and after SMOTE\n",
    "print(f'Accuracy before SMOTE: {round(accuracy_test * 100, 2)}%')\n",
    "print(f'Accuracy after SMOTE: {round(accuracy_after_smote * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model on the resampled data (after SMOTE)\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predictions on the test set\n",
    "y_pred_resampled = svm_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the performance of the model on the test data\n",
    "print('SVM with SMOTE Classification report:\\n', classification_report(y_test_luxury_beauty, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from functools import lru_cache\n",
    "import keras_tuner as kt\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_beauty = \"AMAZON/All_Beauty_5.json\"\n",
    "Fash = \"AMAZON/AMAZON_FASHION_5.json\"\n",
    "Lux = \"AMAZON/Luxury_Beauty_5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(json_path):\n",
    "    data = []\n",
    "\n",
    "    with open(json_path) as f:\n",
    "        \n",
    "        for line in f:\n",
    "            doc = json.loads(line)\n",
    "            #skip lines with None data, as it would be filtered out anyway\n",
    "            if 'overall' in doc and 'reviewText' in doc and 'summary' in doc:\n",
    "                lst = [doc['overall'], doc['reviewText'], doc['summary']]\n",
    "                data.append(lst)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_df(paths):\n",
    "    full = []\n",
    "    for p in paths:\n",
    "        full.extend(get_cols(p))\n",
    "    return(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(create_full_df([All_beauty, Fash]), columns=['overall', 'reviewText', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_df[\"overall\"])\n",
    "plt.title(\"Positive review skew\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = data_resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting relevant stopword packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.remove(\"not\") #as with shallow learners, not might imply negative review\n",
    "stopwords = set(stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmatize = lru_cache(maxsize=50000)(wnl.lemmatize) #cahceing might increase performance\n",
    "stemmed_list = []\n",
    "words_to_lemmatize = [\"n\", \"v\", \"r\", \"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_words(word_list, words_to_lemmatize, stopwords, lemmatizer):\n",
    "    cleaned_list = []\n",
    "    for i in word_list:\n",
    "        new_string = ''.join((x for x in i if not x.isdigit()))\n",
    "        word_tokens = word_tokenize(new_string)\n",
    "        # converts the words in word_tokens to lower case and then checks whether \n",
    "        #they are present in stop_words or not\n",
    "        filtered_sentence = [w for w in word_tokens if w.lower() not in stopwords]\n",
    "        for j in words_to_lemmatize:\n",
    "            stem = [lemmatizer(word, j) for word in filtered_sentence]\n",
    "        #stems sentences after stopwords are removed\n",
    "        cleaned_list.append(' '.join(stem))\n",
    "\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"cleaned\"] = preprocess_words(full_df[\"reviewText\"], words_to_lemmatize, stopwords, lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lux_df = pd.DataFrame(get_cols(Lux), columns=[\"overall\", \"reviewText\", \"summary\"])\n",
    "lux_df[\"negative\"] = lux_df[\"overall\"].apply(lambda x: 1 if x <= 3 else 0)\n",
    "lux_df[\"cleaned\"] = preprocess_words(lux_df[\"reviewText\"], words_to_lemmatize, stopwords, lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = full_df[\"cleaned\"]\n",
    "max_tokens = 5214 \n",
    "output_sequence_length = 209 # adapted from the shallow learner EDA\n",
    "pad_to_max_tokens = True\n",
    "\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens,\n",
    "                                            output_sequence_length=output_sequence_length,\n",
    "                                            pad_to_max_tokens=pad_to_max_tokens)\n",
    "\n",
    "\n",
    "\n",
    "#Build a vocabulary of all string terms from tokens seen in the dataset.\n",
    "encoder.adapt(list(vocab_list), batch_size=128)\n",
    "\n",
    "#Retrieves the computed vocabulary\n",
    "vocab = np.array(encoder.get_vocabulary()) \n",
    "print(f'The reviews vocabulary: \\n{vocab}\\n')\n",
    "print(f'length of vocabulary: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = full_df[\"cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_train = len(max(reviews, key=len))\n",
    "\n",
    "max_length = max_length_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(full_df['cleaned']), full_df['negative'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_pad(data, max_length):\n",
    "    encoded_example = encoder(data).numpy() \n",
    "    padded_reviews = pad_sequences(encoded_example, maxlen=max_length,\n",
    "                               padding='post')\n",
    "    return padded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_reviews = encode_and_pad(X_train, max_length)\n",
    "test_padded_reviews = encode_and_pad(X_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "def model_builder(hp):\n",
    "    #clearing backend to help memory leakage\n",
    "    K.clear_session()\n",
    "    model = tf.keras.models.Sequential()\n",
    "    hp_embedding_dim = hp.Choice('embedding_dimension', values=[128, 256]) \n",
    "    model.add(tf.keras.layers.Embedding(input_dim=len(vocab), \n",
    "                              output_dim=hp_embedding_dim,\n",
    "                              input_length=max_length,\n",
    "                              name=\"embedding\"))\n",
    "    hp_neurons = hp.Int(\"units_1\", min_value=32, max_value=64, step=16)                         \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hp_neurons, return_sequences=True)))\n",
    "    hp_neurons_2 = hp.Int(\"units_2\", min_value=16, max_value=32, step=16)   \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hp_neurons_2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01])\n",
    "    hp_weight_decay = hp.Choice('weight_decay', values=[0.001, 0.01])\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate, weight_decay=hp_weight_decay)\n",
    "\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', \n",
    "                        metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "                        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "print(f'Tuning will run approximately {round(50 * (math.log(50, 10) ** 2))} epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=5,\n",
    "                     seed=42,\n",
    "                     directory='Tuning results',\n",
    "                     project_name='RNN hyperband tuning1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(train_padded_reviews, y_train, epochs=20, batch_size=256, validation_data=[test_padded_reviews, y_test], callbacks=[es])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Search complete! \n",
    "\\nOptimal amount of neurons in the first biLSTM layer: {best_hps.get('units_1')}\n",
    "\\nOptimal amount of neurons in the second biLSTM layer: {best_hps.get('units_2')}\n",
    "\\nOptimal embedding dimension: {best_hps.get('embedding_dimension')} \n",
    "\\nOptimal learning rate: {best_hps.get('learning_rate')}\n",
    "\\nOptimal weight decay: {best_hps.get('weight_decay')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recording search results\n",
    "\n",
    "encoded manually, so search doesn't have to be run again, if system crashes or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "\n",
    "biLSTM1 = 32\n",
    "\n",
    "biLSTM2 = 32\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "tuned_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(vocab), \n",
    "                              output_dim=embedding_dim,\n",
    "                              input_length=max_length,\n",
    "                              name=\"embedding\"),                      \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(biLSTM1, return_sequences=True), name=\"bidirectional_LSTM_1\"),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(biLSTM2), name=\"bidirectional_LSTM_2\"),\n",
    "    tf.keras.layers.Dropout(0.2, name=\"dropout\"),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name=\"Dense_layer\"),\n",
    "    tf.keras.layers.BatchNormalization(name=\"batch_norm\"),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")\n",
    "    ])\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lr, weight_decay=wd)\n",
    "\n",
    "tuned_model.compile(optimizer=adam, loss='binary_crossentropy', \n",
    "                        metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "                        )\n",
    "\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "tf.keras.utils.plot_model(tuned_model, to_file=\"rnn.png\",  show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=num_epochs*0.2, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = tuned_model.fit(train_padded_reviews, y_train, batch_size=64, epochs=num_epochs, validation_data=(test_padded_reviews, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_min = min(history.history[\"val_loss\"])\n",
    "\n",
    "best_epoch = history.history[\"val_loss\"].index(val_min)\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "plt.scatter(best_epoch, val_min, label=f'minimum loss: {round(val_min, 3)}', color=\"red\")\n",
    "plt.title('Tuned model performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = tuned_model.predict(test_padded_reviews).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='tuned model (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for test data prediction')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_example_test = encoder(lux_df[\"cleaned\"]).numpy() \n",
    "val_padded_reviews = pad_sequences(encoded_example_test, maxlen=max_length,\n",
    "                               padding='post')\n",
    "val_labels = np.array(lux_df[\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.array(lux_df[\"negative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, precision, recall = tuned_model.evaluate(val_padded_reviews, val_labels)\n",
    "\n",
    "print(f'loss: {loss}\\naccuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tuned_model.predict(val_padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = prediction.ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(val_labels, y_pred_keras)\n",
    "auc_score = auc(fpr_keras, tpr_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = prediction.ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(val_labels, y_pred_keras)\n",
    "auc_score = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='tuned model (area = {:.3f})'.format(auc_score))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for luxury beauty prediction')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.save('Models/tuned_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "GRU_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(vocab), \n",
    "                              output_dim=128,\n",
    "                              input_length=max_length,\n",
    "                              name=\"embedding\"),                      \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16), name=\"bidirectional_GRU\"),\n",
    "    tf.keras.layers.Dropout(0.2, name=\"dropout\"),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name=\"Dense_layer\"),\n",
    "    tf.keras.layers.BatchNormalization(name=\"batch_norm\"),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")\n",
    "    ])\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=wd)\n",
    "\n",
    "GRU_model.compile(optimizer=adam, loss='binary_crossentropy', \n",
    "                        metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "                        )\n",
    "\n",
    "GRU_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(GRU_model, to_file=\"rnn2.png\",  show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=num_epochs*0.2, restore_best_weights=True, verbose=1)\n",
    "\n",
    "GRU_history = GRU_model.fit(train_padded_reviews, y_train, batch_size=64, epochs=num_epochs, validation_data=(test_padded_reviews, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_min = min(GRU_history.history[\"val_loss\"])\n",
    "\n",
    "best_epoch = GRU_history.history[\"val_loss\"].index(val_min)\n",
    "\n",
    "plt.plot(GRU_history.history['loss'], label=\"loss\")\n",
    "plt.plot(GRU_history.history['val_loss'], label=\"val_loss\")\n",
    "plt.scatter(best_epoch, val_min, label=f'minimum loss: {round(val_min, 3)}', color=\"red\")\n",
    "plt.title('GRU model performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(GRU_history.history['accuracy'], label=\"accuracy\")\n",
    "plt.plot(GRU_history.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.vlines(best_epoch, ymin=min(history.history[\"accuracy\"]), ymax=1, label=\"best epoch\", linestyle=\"dotted\", color=\"red\")\n",
    "plt.title(\"GRU model accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = GRU_model.predict(test_padded_reviews).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='GRU model (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for test data prediction')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, precision, recall = GRU_model.evaluate(val_padded_reviews, val_labels)\n",
    "\n",
    "print(f'loss: {loss}\\naccuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = GRU_model.predict(val_padded_reviews)\n",
    "y_pred_keras = prediction.ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(val_labels, y_pred_keras)\n",
    "auc_score = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='GRU model (area = {:.3f})'.format(auc_score))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for luxury beauty prediction')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_model.save('Models/GRU_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
